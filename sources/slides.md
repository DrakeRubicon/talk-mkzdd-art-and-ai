# Slides

## Slide #1 – "Kunst und KI – Wo bleibt der Künstler?"

* [Themenabend: Künstliche Intelligenz @ Medienkulturzentrum Dresden (Facebook-Event)](https://www.facebook.com/events/961534098359732/?ref=newsfeed&locale=de_DE)

## Slide #2 – "Drake Rubicon"

* [Drake Rubicon @ Instagram](https://www.instagram.com/drake_rubicon/)
* [Drake Rubicon @ Github](https://github.com/DrakeRubicon)
* [Constitute Reality @ C.Rockefeller Center for the contemporary arts](https://www.crockefeller.org/allgemein/constitute-reality-david-jaehnel-drake-rubicon-richard-roeder/)
* [Constitute Reality @ DCA](https://dresdencontemporaryart.com/events/vernissage-am-28-9-2017-20-uhr-constitute-reality/)
* [Meta Marathon : AI (Facebook-Event)](https://www.facebook.com/events/nrw-forum-d%C3%BCsseldorf/meta-marathon-2018-ai/799069533619166/)\
* [Paper: "System zur Visualisierung von Lernvorgängen in neuralen Netzen" - Jīva AI](https://www.dropbox.com/sh/mj2wlbhn7eb6gqj/AAC_TyW_qjsdln0d1y7yIli7a?dl=0)
* ["re:draw" @ Kurator: Thomas Hellinger](https://thomas-hellinger.de/biografie/kuratorentaetigkeit/)
* ["re:draw" @ Künstlermesse-Dresden via archive.org](https://web.archive.org/web/20220528224005/https://kuenstlermesse-dresden.de/rahmenprogramm-2022/)


## Slide #3 – "Struktur"

* No Links

## Slide #4 – "Zeitlinie"

### ImageNet

* [Official Website](https://image-net.org/index.php)
* ["ImageNet: A Large-Scale Hierarchical Image Database" – Original Publication @ IEEE](https://www.image-net.org/static_files/papers/imagenet_cvpr09.pdf)
* [ImageNet @ Wikipedia](https://en.wikipedia.org/wiki/ImageNet)

### Watson

* [IBM Watson](https://www.ibm.com/watson)
* [IBM Watson @ Wikipedia](https://en.wikipedia.org/wiki/IBM_Watson)
* [IBM Watson Jeopardy Challenge @ YouTube](https://www.youtube.com/watch?v=P18EdAKuC1U)
* ["Computer Wins on ‘Jeopardy!’: Trivial, It’s Not" @ NYTimes](https://www.nytimes.com/2011/02/17/science/17jeopardy-watson.html)

### GAN – "Generative Adversarial Network"

* ["Generative Adversarial Nets" Original Paper](https://proceedings.neurips.cc/paper_files/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf)
* [GAN @ Wikipedia](https://en.wikipedia.org/wiki/Generative_adversarial_network)

### Google Deep Dream

* [Deep Dream @ Wikipedia](https://en.wikipedia.org/wiki/DeepDream)
* [Deep Dream @ Github](https://github.com/google/deepdream)
* [Deep Dream @ Google AI](https://ai.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html)

### StyleTransfer

* [Neural Style Transfer @ Wikipedia](https://en.wikipedia.org/wiki/Neural_style_transfer)
* ["Image Style Transfer Using Convolutional Neural Networks" – Original Paper](https://arxiv.org/abs/1508.06576)

### Transformer

* [Transformer @ Wikipedia](https://en.wikipedia.org/wiki/Transformer_(machine_learning_model))
* ["Attention Is All You Need" - Original paper](https://arxiv.org/abs/1706.03762)
* [Transformer @ Google AI](https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html)

### GPT-1 (Generative Pre-trained Transformer)

* [GPT @ Wikipedia](https://en.wikipedia.org/wiki/Generative_pre-trained_transformer)
* [GPT-1 https://github.com/openai/finetune-transformer-lmCode + Model @ Github]()
* [Introduction @ OpenAi via archive.org](https://web.archive.org/web/20230318210736/https://openai.com/research/language-unsupervised)

### StyleGAN

* [StyleGAN @ Wikipedia](https://en.wikipedia.org/wiki/StyleGAN)
* [StyleGAN – Original Paper](https://arxiv.org/abs/1812.04948)
* [StyleGAN @ Github](https://github.com/NVlabs/stylegan)

### GPT-2

* [GPT-2 – Original Paper](https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf)
* [GPT-2 Releasepost @ OpenAI via archive.org](https://web.archive.org/web/20201219132206/https://openai.com/blog/better-language-models/)
* [GPT-2 Code @ Github](https://github.com/openai/gpt-2)
* [GTP-2 @ Wikipedia](https://en.wikipedia.org/wiki/GPT-2)


### GPT-3

* [GTP-3 @ Wikipedia](https://en.wikipedia.org/wiki/GPT-3)
* [GPT-3 @ Github](https://github.com/openai/gpt-3)
* [GPT-3 – Original Paper](https://arxiv.org/abs/2005.14165)

### DALL-E

* []()
* []()
* []()
* []()

### LAION-400M

* []()
* []()
* []()
* []()

### ChatGPT

* []()
* []()
* []()
* []()


### Midjourney

* []()
* []()
* []()
* []()

### Dall-E 2

* []()
* []()
* []()
* []()

### ImageGen

* []()
* []()
* []()
* []()

### Laion-5B

* []()
* []()
* []()
* []()

### StableDiffusion 1 & 2

* []()
* []()
* []()
* []()

### ControlNet

* []()
* []()
* []()
* []()

### GPT-4

* []()
* []()
* []()
* []()


### LLaMA
* []()
* []()
* []()

## Slide #5 – "Struktur"



## Slide #6 – "Struktur"
## Slide #7 – "Struktur"
## Slide #8 – "Reaktionen"

* No Links

## Slide #9 – "Struktur"
## Slide #10 – "Struktur"
## Slide #11 – "Struktur"
## Slide #12 – "Struktur"
## Slide #13 – "Struktur"
## Slide #14 – "Struktur"
## Slide #15 – "Vergangenheit & Zukunft"

* No Links

## Slide #16 – "Struktur"
## Slide #17 – "Struktur"
## Slide #18 – "Struktur"
## Slide #19 – "Struktur"
## Slide #20 – "Ausblick"

* No Links

## Slide #21 – "Q&A"

* No Links