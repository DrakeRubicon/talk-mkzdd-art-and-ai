# Slides

## Slide #1 – "Kunst und KI – Wo bleibt der Künstler?"
* [Themenabend: Künstliche Intelligenz @ Medienkulturzentrum Dresden (Facebook-Event)](https://www.facebook.com/events/961534098359732/?ref=newsfeed&locale=de_DE)
## Slide #2 – "Drake Rubicon"
* [Drake Rubicon @ Instagram](https://www.instagram.com/drake_rubicon/)
* [Drake Rubicon @ Github](https://github.com/DrakeRubicon)
* [Constitute Reality @ C.Rockefeller Center for the contemporary arts](https://www.crockefeller.org/allgemein/constitute-reality-david-jaehnel-drake-rubicon-richard-roeder/)
* [Constitute Reality @ DCA](https://dresdencontemporaryart.com/events/vernissage-am-28-9-2017-20-uhr-constitute-reality/)
* [Meta Marathon : AI (Facebook-Event)](https://www.facebook.com/events/nrw-forum-d%C3%BCsseldorf/meta-marathon-2018-ai/799069533619166/)\
* [Paper: "System zur Visualisierung von Lernvorgängen in neuralen Netzen" - Jīva AI](https://www.dropbox.com/sh/mj2wlbhn7eb6gqj/AAC_TyW_qjsdln0d1y7yIli7a?dl=0)
* ["re:draw" @ Kurator: Thomas Hellinger](https://thomas-hellinger.de/biografie/kuratorentaetigkeit/)
* ["re:draw" @ Künstlermesse-Dresden via archive.org](https://web.archive.org/web/20220528224005/https://kuenstlermesse-dresden.de/rahmenprogramm-2022/)

## Slide #3 – "Struktur"
* No Links
## Slide #4 – "Zeitlinie"
### ImageNet
* [Official Website](https://image-net.org/index.php)
* ["ImageNet: A Large-Scale Hierarchical Image Database" – Original Publication @ IEEE](https://www.image-net.org/static_files/papers/imagenet_cvpr09.pdf)
* [ImageNet @ Wikipedia](https://en.wikipedia.org/wiki/ImageNet)
### Watson
* [IBM Watson](https://www.ibm.com/watson)
* [IBM Watson @ Wikipedia](https://en.wikipedia.org/wiki/IBM_Watson)
* [IBM Watson Jeopardy Challenge @ YouTube](https://www.youtube.com/watch?v=P18EdAKuC1U)
* ["Computer Wins on ‘Jeopardy!’: Trivial, It’s Not" @ NYTimes](https://www.nytimes.com/2011/02/17/science/17jeopardy-watson.html)
### GAN – "Generative Adversarial Network"
* ["Generative Adversarial Nets" Original Paper](https://proceedings.neurips.cc/paper_files/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf)
* [GAN @ Wikipedia](https://en.wikipedia.org/wiki/Generative_adversarial_network)
### Google Deep Dream
* [Deep Dream @ Wikipedia](https://en.wikipedia.org/wiki/DeepDream)
* [Deep Dream @ Github](https://github.com/google/deepdream)
* [Deep Dream @ Google AI](https://ai.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html)
### StyleTransfer
* [Neural Style Transfer @ Wikipedia](https://en.wikipedia.org/wiki/Neural_style_transfer)
* ["Image Style Transfer Using Convolutional Neural Networks" – Original Paper](https://arxiv.org/abs/1508.06576)
### Transformer
* [Transformer @ Wikipedia](https://en.wikipedia.org/wiki/Transformer_(machine_learning_model))
* ["Attention Is All You Need" - Original paper](https://arxiv.org/abs/1706.03762)
* [Transformer @ Google AI](https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html)
### GPT-1 (Generative Pre-trained Transformer)
* [GPT @ Wikipedia](https://en.wikipedia.org/wiki/Generative_pre-trained_transformer)
* [GPT-1 https://github.com/openai/finetune-transformer-lmCode + Model @ Github]()
* [Introduction @ OpenAi via archive.org](https://web.archive.org/web/20230318210736/https://openai.com/research/language-unsupervised)
### StyleGAN
* [StyleGAN @ Wikipedia](https://en.wikipedia.org/wiki/StyleGAN)
* [StyleGAN – Original Paper](https://arxiv.org/abs/1812.04948)
* [StyleGAN @ Github](https://github.com/NVlabs/stylegan)
### GPT-2
* [GPT-2 – Original Paper](https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf)
* [GPT-2 Releasepost @ OpenAI via archive.org](https://web.archive.org/web/20201219132206/https://openai.com/blog/better-language-models/)
* [GPT-2 Code @ Github](https://github.com/openai/gpt-2)
* [GTP-2 @ Wikipedia](https://en.wikipedia.org/wiki/GPT-2)

### GPT-3
* [GTP-3 @ Wikipedia](https://en.wikipedia.org/wiki/GPT-3)
* [GPT-3 @ Github](https://github.com/openai/gpt-3)
* [GPT-3 – Original Paper](https://arxiv.org/abs/2005.14165)
### DALL-E
* [DALL-E @ Wikipedia](https://en.wikipedia.org/wiki/DALL-E)
* [DALL-E Introduction @ OpenAi via archive.org](https://web.archive.org/web/20210105220328/https://openai.com/blog/dall-e/)

### LAION-400M (Large-scale Artificial Intelligence Open Network)
* [LAION @ Wikipedia](https://en.wikipedia.org/wiki/LAION)
* [LAION-400M @ Laion.ai](https://laion.ai/blog/laion-400-open-dataset/)
* [LAION-400M Original Paper](https://arxiv.org/abs/2111.02114)
* [LAION-400M @ HugginFace](https://huggingface.co/datasets/laion/laion400m)

### ChatGPT
* [ChatGPT @ Wikipedia](https://en.wikipedia.org/wiki/ChatGPThttps://web.archive.org/web/20230504032613/https://help.openai.com/en/articles/6825453-chatgpt-release-notes)
* [ChatGPT @ OpenAi via archive.org]()

### Midjourney
* [Midjourney @ Wikipedia](https://en.wikipedia.org/wiki/Midjourney)
* [Midjourney Homepage](https://www.midjourney.com/)
* [Midjourney Discod](https://discord.com/invite/midjourney)
### Dall-E 2
* [DALL-E 2 @ Wikipedia](https://en.wikipedia.org/wiki/DALL-E)
* [DALL-E 2 @ OpenAI](https://openai.com/product/dall-e-2)

### ImageGen
* [ImageGen @ Google Research](https://imagen.research.google/)

### Laion-5B
* [LAION @ Wikipedia](https://en.wikipedia.org/wiki/LAION)
* [Laion-5B @ Laion.ai](https://laion.ai/blog/laion-5b/)
* [Laion-5B Original Paper](https://arxiv.org/abs/2210.08402)
* [Laion-5B @ HugginFace](https://huggingface.co/datasets/laion/laion5B-index)

### StableDiffusion 1 & 2
* [StableDiffusion Web](https://stablediffusionweb.com/)
* [StableDiffusion Release Post @ Stability.Ai](https://stability.ai/blog/stable-diffusion-public-release)
* [StableDiffusion Initial Announcement @ Stability.Ai via archive.org](https://web.archive.org/web/20220905105009/https://stability.ai/blog/stable-diffusion-announcement)
* [StableDiffusion @ Wikipedia](https://en.wikipedia.org/wiki/Stable_Diffusion)
* [Latent Diffusion Models Paper](https://arxiv.org/abs/2112.10752)

### ControlNet
* []()
* []()
* []()
* []()
### GPT-4
* []()
* []()
* []()
* []()

### LLaMA
* []()
* []()
* []()
## Slide #5 – "Funktionsprinzipien"
* []()
* []()
* []()
* []()
## Slide #6 – "Funktionsprinzipien #2"
* []()
* []()
* []()
* []()
## Slide #7 – "Interaktionsprinzipien"
* []()
* []()
* []()
* []()

## Slide #8 – "Reaktionen #1"
* No Links
## Slide #9 – "Reaktionen #2 – Konsumenten"
* []()
* []()
* []()
* []()

## Slide #10 – "Reaktionen #3 – Kreativwirtschaft"
* []()
* []()
* []()
* []()

## Slide #11 – "Reaktionen #4 – Kulturschaffende & bildende Kunst"
* []()
* []()
* []()
* []()

## Slide #12 – "Reaktionen #5 – Medienunternehmen"
* []()
* []()
* []()
* []()

## Slide #13 – "Reaktionen #6 – Politik"
* []()
* []()
* []()
* []()

## Slide #14 – "Reaktionen #7 – KI-Unternehmen"
* []()
* []()
* []()
* []()

## Slide #15 – "Vergangenheit & Zukunft"
* No Links
## Slide #16 – "Historischer Wert von Kunst"
* []()
* []()
* []()
* []()

## Slide #17 – "Kunst- und Kulturschaffende"
* []()
* []()
* []()
* []()

## Slide #18 – "Schaffenshöhe"
* []()
* []()
* []()
* []()

## Slide #19 – "Digitalisierung und die 90’er"
* []()
* []()
* []()
* []()

## Slide #20 – "Ausblick"
* No Links
## Slide #21 – "Q&A"
* No Links